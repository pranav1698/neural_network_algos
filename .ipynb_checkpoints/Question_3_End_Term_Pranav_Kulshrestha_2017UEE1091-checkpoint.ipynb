{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "fZ9qKGqvZCC7"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "owDex-h8ZCpn"
   },
   "outputs": [],
   "source": [
    "# Defining the activation function \n",
    "# \n",
    "# Method Signature: \n",
    "#   - Definition: Takes the value and returns the sum upto one #   - Parameters: Input Value(xin) \n",
    "#   - Return Value: Returns the value rounded upto 1\n",
    "\n",
    "def sigmoid(X):\n",
    "  return 1/(1 + np.exp(-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "T0hSRPRjZH95"
   },
   "outputs": [],
   "source": [
    "# The Neural Network Function\n",
    "#\n",
    "# Method Signature: \n",
    "#   - Definition: According to the number of epochs, this will train the neural\n",
    "#                 network by feed-forward and backpropagation \n",
    "#   - Parameters: Input Matrice(X), Target Matrix(T), Weight Matrix(W1 & W2)\n",
    "#                 number of iterations(num_epochs)\n",
    "#   - Return Value: None \n",
    "\n",
    "def NN(X, T, W1, W2, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        # Calculating output of the hidden layer\n",
    "        l1_output = sigmoid(np.dot(X, W1))\n",
    "        l2_output = sigmoid(np.dot(l1_output, W2))\n",
    "\n",
    "        # Calculating error for the output layer\n",
    "        l2_err = T - l2_output\n",
    "        # Calculating the change in error for the ouput layer\n",
    "        l2_delta = l2_err * l2_output * (1 - l2_output)\n",
    "        \n",
    "        # Calculating the error for the hidden layer\n",
    "        l1_err = np.dot(l2_delta, W2.T)\n",
    "        # Calculating the change in error for the hidden layer\n",
    "        l1_delta = l1_err * l1_output * (1 - l1_output)\n",
    "\n",
    "        # Backpropagating the error to find the change in weight\n",
    "        W1 += np.dot(X.T, l1_delta)\n",
    "        W2 += np.dot(l1_output.T, l2_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "Ws-h1kuibL8v"
   },
   "outputs": [],
   "source": [
    "# Defining the input and target matrix for a XOR neural network\n",
    "X = np.array([[0,0], [1,0], [0, 1], [1, 1]])\n",
    "T = np.array([[0, 1, 1, 0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "oquST0o7bQnF"
   },
   "outputs": [],
   "source": [
    "# Defining input dimensions, dimensions of the hidden layer and that of the\n",
    "# output layer\n",
    "input_dim = 2\n",
    "hidden_dim = 6\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "TQOxAonUblwe"
   },
   "outputs": [],
   "source": [
    "# Defining random matrices for the hidden layer and the output layer\n",
    "W1 = np.random.random((input_dim, hidden_dim))\n",
    "W2 = np.random.random((hidden_dim, output_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "8JTFm00tbxpd"
   },
   "outputs": [],
   "source": [
    "# Running the neural network to get the weights after 2 iterations\n",
    "NN(X, T, W1, W2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WfN-e3CFb7e-",
    "outputId": "0a3fca43-56e4-4c02-d421-94a0cf00fbdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.060929   0.72966657 0.02587722 0.878642   0.19604123 0.87638786]\n",
      " [0.37891467 0.07202594 0.69469801 0.17391964 0.70911218 0.59695352]]\n",
      "[[0.54034237]\n",
      " [0.70145787]\n",
      " [0.07554517]\n",
      " [0.79220333]\n",
      " [0.53726564]\n",
      " [0.46037185]]\n"
     ]
    }
   ],
   "source": [
    "# After running the Backpropagation Algorithm for 2 iterations we get the\n",
    "# following value of W1 and W2\n",
    "print(W1)\n",
    "print(W2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
