{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "fZ9qKGqvZCC7"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "owDex-h8ZCpn"
   },
   "outputs": [],
   "source": [
    "# Defining the activation function \n",
    "# \n",
    "# Method Signature: \n",
    "#   - Definition: Takes the value and returns the sum upto one #   \n",
    "#   - Parameters: Input Value(xin) \n",
    "#   - Return Value: Returns the value rounded upto 1\n",
    "\n",
    "def sigmoid(X):\n",
    "  return 1/(1 + np.exp(-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "T0hSRPRjZH95"
   },
   "outputs": [],
   "source": [
    "# The Neural Network Function\n",
    "#\n",
    "# Method Signature: \n",
    "#   - Definition: According to the number of epochs, this will train the neural\n",
    "#                 network by feed-forward and backpropagation \n",
    "#   - Parameters: Input Matrice(X), Target Matrix(T), Weight Matrix(W1 & W2), learning_rate(learning_rate),\n",
    "#                 number of iterations(num_epochs)\n",
    "#   - Return Value: None \n",
    "\n",
    "def NN(X, T, W1, W2, learning_rate, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        # Calculating output of the hidden layer\n",
    "        l1_output = sigmoid(np.dot(X, W1))\n",
    "        l2_output = sigmoid(np.dot(l1_output, W2))\n",
    "\n",
    "        # Calculating error for the output layer\n",
    "        l2_err = T - l2_output\n",
    "        # Calculating the change in error for the ouput layer\n",
    "        l2_delta = l2_err * l2_output * (1 - l2_output)\n",
    "        \n",
    "        # Calculating the error for the hidden layer\n",
    "        l1_err = np.dot(l2_delta, W2.T)\n",
    "        # Calculating the change in error for the hidden layer\n",
    "        l1_delta = l1_err * l1_output * (1 - l1_output)\n",
    "\n",
    "        # Backpropagating the error to find the change in weight\n",
    "        W1 += learning_rate * np.dot(X.T, l1_delta)\n",
    "        W2 += learning_rate * np.dot(l1_output.T, l2_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Ws-h1kuibL8v"
   },
   "outputs": [],
   "source": [
    "# Defining the input and target matrix for the given neural network\n",
    "X = np.array([[1, 1], [2, 2], [3, 3], [4, 2]])\n",
    "T = np.array([[0, 1, 1, 0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "oquST0o7bQnF"
   },
   "outputs": [],
   "source": [
    "# Defining input dimensions, dimensions of the hidden layer and that of the\n",
    "# output layer\n",
    "input_dim = 2\n",
    "hidden_dim = 6\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "TQOxAonUblwe"
   },
   "outputs": [],
   "source": [
    "# Defining random matrices for the hidden layer and the output layer\n",
    "W1 = np.random.random((input_dim, hidden_dim))\n",
    "W2 = np.random.random((hidden_dim, output_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "8JTFm00tbxpd"
   },
   "outputs": [],
   "source": [
    "# Running the neural network to get the weights after 2 iterations\n",
    "NN(X, T, W1, W2, 0.2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WfN-e3CFb7e-",
    "outputId": "0a3fca43-56e4-4c02-d421-94a0cf00fbdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.43297306 0.86909555 0.44489215 0.38216477 0.32430543 0.75499617]\n",
      " [0.47250039 0.09014887 0.21112341 0.0721057  0.16757344 0.37055557]]\n",
      "[[0.69948344]\n",
      " [0.76297392]\n",
      " [0.97590915]\n",
      " [0.8485894 ]\n",
      " [0.01447041]\n",
      " [0.79289857]]\n"
     ]
    }
   ],
   "source": [
    "# After running the Backpropagation Algorithm for 2 iterations we get the\n",
    "# following value of W1 and W2\n",
    "print(W1)\n",
    "print(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note; The following classifies the above datapoints, \n",
    "# and found the following weights after two iterations"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
